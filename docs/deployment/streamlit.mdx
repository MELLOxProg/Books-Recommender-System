---
title: 'Streamlit Deployment'
description: 'Deploy your Book Recommender System using Streamlit Cloud and other platforms'
---

## Streamlit Cloud Deployment

Deploy your Book Recommender System to **Streamlit Cloud** for free hosting with automatic updates from your GitHub repository.

<img
  src="/demo/1.png"
  alt="Book Recommender System running on Streamlit"
/>

### Prerequisites

<AccordionGroup>
  <Accordion title="Repository Setup">
    - GitHub repository with your Book Recommender System
    - All model artifacts (`artifacts/*.pkl` files) included in the repo
    - Valid `requirements.txt` file
    - `app.py` as the main Streamlit application
  </Accordion>

  <Accordion title="Account Requirements">
    - GitHub account with the repository
    - Streamlit Cloud account (free at share.streamlit.io)
    - Repository should be public or you have Streamlit Teams/Enterprise
  </Accordion>
</AccordionGroup>

### Step-by-Step Deployment

<Steps>
  <Step title="Prepare Your Repository">
    Ensure your repository structure matches the required format:
    
    ```
    Books-Recommender-System/
    â”œâ”€â”€ app.py                    # Main Streamlit app
    â”œâ”€â”€ requirements.txt          # Dependencies
    â”œâ”€â”€ artifacts/               # Model files
    â”‚   â”œâ”€â”€ model.pkl
    â”‚   â”œâ”€â”€ book_names.pkl
    â”‚   â”œâ”€â”€ book_pivot.pkl
    â”‚   â””â”€â”€ final_rating.pkl
    â”œâ”€â”€ data/                    # Dataset files (optional for deployment)
    â””â”€â”€ README.md
    ```
  </Step>

  <Step title="Optimize Requirements">
    Create a minimal `requirements.txt` for faster deployment:
    
    ```txt
    streamlit>=1.28.0
    numpy>=1.21.0
    pandas>=1.3.0
    scikit-learn>=1.0.0
    ```
    
    <Note>
      Avoid including unnecessary packages to reduce deployment time and memory usage.
    </Note>
  </Step>

  <Step title="Deploy to Streamlit Cloud">
    1. Go to [share.streamlit.io](https://share.streamlit.io)
    2. Sign in with your GitHub account
    3. Click "New app"
    4. Select your repository: `MELLOxProg/Books-Recommender-System`
    5. Set main file path: `app.py`
    6. Choose a custom URL (optional)
    7. Click "Deploy!"
  </Step>

  <Step title="Monitor Deployment">
    Watch the deployment logs for any issues:
    
    ```bash
    # Common deployment stages
    [INFO] Cloning repository...
    [INFO] Installing dependencies...
    [INFO] Starting Streamlit app...
    [SUCCESS] App is live at: https://your-app.streamlit.app
    ```
  </Step>
</Steps>

### Configuration Options

<Tabs>
  <Tab title="Environment Variables">
    Set environment variables in Streamlit Cloud dashboard for sensitive configurations:
    
    ```python path=/app.py start=1
    import os
    import streamlit as st
    
    # Configuration with environment variables
    MODEL_PATH = os.getenv('MODEL_PATH', 'artifacts/')
    DEBUG_MODE = os.getenv('DEBUG', 'False').lower() == 'true'
    
    # Use in your app
    if DEBUG_MODE:
        st.sidebar.text("Debug mode enabled")
    ```
  </Tab>

  <Tab title="Streamlit Config">
    Add `.streamlit/config.toml` for app-specific settings:
    
    ```toml
    [global]
    dataFrameSerialization = "legacy"
    
    [server]
    runOnSave = true
    enableCORS = false
    enableWebsocketCompression = true
    
    [browser]
    gatherUsageStats = false
    
    [theme]
    primaryColor = "#0D9373"
    backgroundColor = "#FFFFFF"
    secondaryBackgroundColor = "#F0F2F6"
    textColor = "#262730"
    ```
  </Tab>

  <Tab title="Secrets Management">
    Store sensitive information using Streamlit secrets:
    
    ```python path=null start=null
    # In your app.py
    import streamlit as st
    
    # Access secrets (configure in Streamlit Cloud dashboard)
    api_key = st.secrets["api_key"]
    database_url = st.secrets["database"]["url"]
    
    # Or use TOML format in .streamlit/secrets.toml (local only)
    # api_key = "your-api-key"
    # [database]
    # url = "your-database-url"
    ```
  </Tab>
</Tabs>

## Local Development

### Running Locally

Set up your local development environment:

<CodeGroup>

```bash Windows (PowerShell)
# Clone repository
git clone https://github.com/MELLOxProg/Books-Recommender-System.git
cd Books-Recommender-System

# Create virtual environment
python -m venv venv
venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run Streamlit app
streamlit run app.py
```

```bash macOS/Linux
# Clone repository
git clone https://github.com/MELLOxProg/Books-Recommender-System.git
cd Books-Recommender-System

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run Streamlit app
streamlit run app.py
```

```bash Using Conda
# Clone repository
git clone https://github.com/MELLOxProg/Books-Recommender-System.git
cd Books-Recommender-System

# Create conda environment
conda create -n books python=3.9 -y
conda activate books

# Install dependencies
pip install -r requirements.txt

# Run Streamlit app
streamlit run app.py
```

</CodeGroup>

### Development Tips

<AccordionGroup>
  <Accordion title="Hot Reloading">
    Streamlit automatically reloads when you save changes. For better development experience:
    
    ```python path=null start=null
    # Add this to enable faster reloading
    import streamlit as st
    
    # Cache expensive operations
    @st.cache_data
    def load_model_artifacts():
        import pickle
        model = pickle.load(open('artifacts/model.pkl', 'rb'))
        book_names = pickle.load(open('artifacts/book_names.pkl', 'rb'))
        return model, book_names
    
    # Use cached loading
    model, book_names = load_model_artifacts()
    ```
  </Accordion>

  <Accordion title="Debug Mode">
    Add debug features for development:
    
    ```python path=null start=null
    import streamlit as st
    import os
    
    DEBUG = os.getenv('DEBUG', 'False').lower() == 'true'
    
    if DEBUG:
        st.sidebar.subheader("Debug Info")
        st.sidebar.json({
            "Model loaded": model is not None,
            "Books available": len(book_names),
            "Matrix shape": book_pivot.shape
        })
    ```
  </Accordion>

  <Accordion title="Performance Monitoring">
    Monitor app performance during development:
    
    ```python path=null start=null
    import time
    import streamlit as st
    
    def monitor_performance(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            result = func(*args, **kwargs)
            end_time = time.time()
            
            if 'performance_times' not in st.session_state:
                st.session_state.performance_times = []
            
            st.session_state.performance_times.append({
                'function': func.__name__,
                'duration': end_time - start_time
            })
            
            return result
        return wrapper
    
    # Use decorator on slow functions
    @monitor_performance
    def recommend_book(book_name):
        # Your recommendation logic here
        pass
    ```
  </Accordion>
</AccordionGroup>

## Deployment Troubleshooting

### Common Issues and Solutions

<Warning>
  **Large File Issues**: GitHub and Streamlit Cloud have file size limits that may affect deployment.
</Warning>

<AccordionGroup>
  <Accordion title="File Size Limits">
    **Problem**: Model artifacts are too large (>100MB total)
    
    **Solutions**:
    
    ```python path=null start=null
    # Option 1: Use Git LFS for large files
    # Install git-lfs and track large files
    git lfs track "*.pkl"
    git lfs track "data/*.csv"
    
    # Option 2: Download models on startup
    import urllib.request
    import os
    
    def download_model_if_needed():
        model_url = "https://your-storage.com/model.pkl"
        model_path = "artifacts/model.pkl"
        
        if not os.path.exists(model_path):
            st.info("Downloading model files...")
            urllib.request.urlretrieve(model_url, model_path)
            st.success("Model downloaded!")
    
    # Option 3: Use cloud storage
    import boto3  # or Google Cloud Storage
    
    @st.cache_resource
    def load_model_from_s3():
        s3 = boto3.client('s3')
        s3.download_file('your-bucket', 'model.pkl', '/tmp/model.pkl')
        return pickle.load(open('/tmp/model.pkl', 'rb'))
    ```
  </Accordion>

  <Accordion title="Memory Issues">
    **Problem**: App crashes due to memory limits
    
    **Solutions**:
    
    ```python path=null start=null
    # Optimize memory usage
    import gc
    
    @st.cache_data
    def load_optimized_data():
        # Load only essential data
        book_names = pickle.load(open('artifacts/book_names.pkl', 'rb'))
        # Don't load full pivot matrix if not needed
        return book_names
    
    # Clear unused variables
    def cleanup_memory():
        gc.collect()
        
    # Use session state efficiently
    if 'model' not in st.session_state:
        st.session_state.model = pickle.load(open('artifacts/model.pkl', 'rb'))
    ```
  </Accordion>

  <Accordion title="Dependency Conflicts">
    **Problem**: Package version conflicts during installation
    
    **Solutions**:
    
    ```txt
    # Pin specific versions in requirements.txt
    streamlit==1.28.1
    numpy==1.24.3
    pandas==2.0.3
    scikit-learn==1.3.0
    
    # Or use compatible versions
    streamlit>=1.28.0,<1.29.0
    numpy>=1.21.0,<1.25.0
    pandas>=1.3.0,<2.1.0
    scikit-learn>=1.0.0,<1.4.0
    ```
    
    Test locally before deployment:
    ```bash
    pip install --upgrade -r requirements.txt
    streamlit run app.py
    ```
  </Accordion>

  <Accordion title="Path Issues">
    **Problem**: File paths not found in deployment
    
    **Solutions**:
    
    ```python path=null start=null
    import os
    import streamlit as st
    
    # Use absolute paths relative to script location
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    MODEL_PATH = os.path.join(BASE_DIR, 'artifacts', 'model.pkl')
    
    # Check file exists before loading
    if os.path.exists(MODEL_PATH):
        model = pickle.load(open(MODEL_PATH, 'rb'))
    else:
        st.error(f"Model file not found at: {MODEL_PATH}")
        st.stop()
    
    # Debug file structure
    if st.sidebar.checkbox("Show file structure"):
        for root, dirs, files in os.walk(BASE_DIR):
            level = root.replace(BASE_DIR, '').count(os.sep)
            indent = ' ' * 2 * level
            st.sidebar.text(f"{indent}{os.path.basename(root)}/")
            subindent = ' ' * 2 * (level + 1)
            for file in files[:5]:  # Limit output
                st.sidebar.text(f"{subindent}{file}")
    ```
  </Accordion>
</AccordionGroup>

## Performance Optimization

### Streamlit-Specific Optimizations

<Tabs>
  <Tab title="Caching Strategies">
    ```python path=null start=null
    import streamlit as st
    
    # Cache model loading (expensive, one-time operation)
    @st.cache_resource
    def load_ml_model():
        import pickle
        return pickle.load(open('artifacts/model.pkl', 'rb'))
    
    # Cache data processing (changes with input)
    @st.cache_data
    def get_book_recommendations(book_name):
        model = load_ml_model()
        # Your recommendation logic
        return recommendations, posters
    
    # Cache with TTL for dynamic data
    @st.cache_data(ttl=3600)  # Cache for 1 hour
    def get_popular_books():
        # Logic to get current popular books
        return popular_books
    ```
  </Tab>

  <Tab title="Session State Management">
    ```python path=null start=null
    # Initialize session state efficiently
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.model = load_ml_model()
        st.session_state.book_names = load_book_names()
        st.session_state.recommendations_cache = {}
    
    # Use cached recommendations
    def get_cached_recommendations(book_name):
        if book_name in st.session_state.recommendations_cache:
            return st.session_state.recommendations_cache[book_name]
        
        recs = generate_recommendations(book_name)
        st.session_state.recommendations_cache[book_name] = recs
        return recs
    ```
  </Tab>

  <Tab title="UI Optimizations">
    ```python path=null start=null
    # Use columns for better layout
    col1, col2, col3 = st.columns([2, 1, 2])
    
    with col1:
        selected_book = st.selectbox("Select a book", book_names)
    
    with col2:
        if st.button("Get Recommendations", type="primary"):
            with st.spinner("Finding similar books..."):
                recs, posters = get_recommendations(selected_book)
    
    with col3:
        st.info("Select a book to get personalized recommendations")
    
    # Show progress for long operations
    if st.button("Retrain Model"):
        progress_bar = st.progress(0)
        for i in range(100):
            # Simulate training steps
            time.sleep(0.01)
            progress_bar.progress(i + 1)
        st.success("Model retrained successfully!")
    ```
  </Tab>
</Tabs>

## Monitoring and Analytics

### Basic Analytics

```python path=null start=null
import streamlit as st
import datetime

# Simple usage tracking
def track_usage(event_type, details=None):
    if 'usage_log' not in st.session_state:
        st.session_state.usage_log = []
    
    st.session_state.usage_log.append({
        'timestamp': datetime.datetime.now(),
        'event': event_type,
        'details': details
    })

# Track user interactions
if st.button("Show Recommendation"):
    track_usage('recommendation_requested', {'book': selected_book})
    # Your recommendation logic here

# Display usage stats (admin only)
if st.sidebar.checkbox("Show Usage Stats", help="Admin only"):
    if 'usage_log' in st.session_state:
        st.sidebar.json({
            'total_requests': len(st.session_state.usage_log),
            'unique_books': len(set(log.get('details', {}).get('book') 
                                  for log in st.session_state.usage_log 
                                  if log.get('details', {}).get('book')))
        })
```

### Health Checks

```python path=null start=null
def health_check():
    """Check if all components are working"""
    checks = {
        'model_loaded': 'model' in st.session_state and st.session_state.model is not None,
        'books_available': len(book_names) > 0,
        'artifacts_present': all(os.path.exists(f'artifacts/{file}') 
                                for file in ['model.pkl', 'book_names.pkl']),
        'memory_usage': 'OK'  # Could add actual memory check
    }
    
    return all(checks.values()), checks

# Show health status
if st.sidebar.checkbox("Health Check"):
    is_healthy, status = health_check()
    status_color = "ðŸŸ¢" if is_healthy else "ðŸ”´"
    st.sidebar.write(f"{status_color} System Status")
    st.sidebar.json(status)
```

Your Book Recommender System is now ready for deployment on Streamlit Cloud with optimized performance and monitoring capabilities!